{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark \n",
    "\n",
    "---\n",
    "__Elo notes__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD (Resilient Distributed Dataset)\n",
    "- Resilient -- if the data in memory is lost, it can be recreated\n",
    "\n",
    "- Distributed -- stored in memory across the cluster\n",
    "\n",
    "- Dataset -- initial data can come from a file or created programmatically\n",
    "\n",
    "\n",
    "•\tRDDs are the fundamental unit of data in Spark\n",
    "\n",
    "•\tRDD is a read-only, partitioned collection of records\n",
    "\n",
    "•\tMost of Spark programming is performing operations on RDDs\n",
    " \n",
    "#### Two types of RDD operations\n",
    "\n",
    "◦\t__Actions__ - return values\n",
    " \n",
    " ▪\tcount\n",
    " \n",
    " ▪\ttake(n)\n",
    " \n",
    "◦\t__Transformations__ - define new RDDs based on the current one\n",
    "\n",
    "▪\tfilter\n",
    "\t\t\n",
    "▪\tmap\n",
    "\t\t\n",
    "▪\treduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "## Spark Basics \n",
    "#### RDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "import multiprocessing\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initiate SparkContext : sc\n",
    "sparkc = ps.SparkContext('local[4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating RDDs from a list\n",
    "rddl= sparkc.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read RDD from a text file\n",
    "rddf = sparkc.textFile('data/cookie_data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quickly check out the first few entries of a potentially enormous RDD without accessing all of the partitions and loading all of the data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{\"Jane\": \"2\"}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first entries\n",
    "rddf.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'{\"Jane\": \"2\"}', u'{\"Jane\": \"1\"}']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddf.take(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that to execute the collect() method on the RDD object (like we do below), your entire dataset must fit in memory on a single machine (we in general don't want to call collect() on very large datasets). The standard workflow when working with RDDs is to perform all the big data operations/transformations before you pool/retrieve the results. If the results can't be collect()ed onto a single machine, it's common to write data out to a distributed storage system, like HDFS or S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'{\"Jane\": \"2\"}',\n",
       " u'{\"Jane\": \"1\"}',\n",
       " u'{\"Pete\": \"20\"}',\n",
       " u'{\"Tyler\": \"3\"}',\n",
       " u'{\"Duncan\": \"4\"}',\n",
       " u'{\"Yuki\": \"5\"}',\n",
       " u'{\"Duncan\": \"6\"}',\n",
       " u'{\"Duncan\": \"4\"}',\n",
       " u'{\"Duncan\": \"5\"}']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: don't call collect() on very large datasets\n",
    "rddf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddl.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "RDD objects are immutable and that anytime we apply a transformation to an RDD (such as map(), reduce(), or filter()) this transformation returns another RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RDD file to (Key, Value)\n",
    "rddf_ = rddf.map(lambda x: (json.loads(x).keys()[0], int(json.loads(x).values()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Jane', 2),\n",
       " (u'Jane', 1),\n",
       " (u'Pete', 20),\n",
       " (u'Tyler', 3),\n",
       " (u'Duncan', 4),\n",
       " (u'Yuki', 5),\n",
       " (u'Duncan', 6),\n",
       " (u'Duncan', 4),\n",
       " (u'Duncan', 5)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddf_.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Pete', 20), (u'Duncan', 6)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddf_.filter(lambda (k, v): v > 5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Jane', 2), (u'Pete', 20), (u'Yuki', 5), (u'Tyler', 3), (u'Duncan', 6)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddf_.reduceByKey(lambda v1, v2: max(v1, v2)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddf_.values().reduce(lambda v1, v2: v1 + v2)*cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
